# LLM Handover Document - Treasure Hunt Analyzer (THA)

**Last Updated**: 2025-12-10 (Comprehensive Audit + All Fixes Applied)
**Project Status**: Development - Critical Discoveries with Detail Panel
**Current Version**: 1.8.2

---

## Quick Navigation

| Document | Purpose |
|----------|---------|
| [FEATURES.md](FEATURES.md) | **Complete feature inventory with status** |
| [CLAUDE.md](CLAUDE.md) | AI Assistant Guide |
| [APPLICATION_FLOW_MAP.md](docs/APPLICATION_FLOW_MAP.md) | Complete workflow diagram with all artifacts |
| [BUSINESS_PROTECTION.md](docs/scoring-rules/BUSINESS_PROTECTION.md) | Severity scores (90/75/60/50) |
| [quantitative-alert.yaml](docs/th-context/analysis-rules/templates/quantitative-alert.yaml) | Report template |

---

## Purpose

This document provides comprehensive project context for AI agents working on the Treasure Hunt Analyzer. It's systematically updated after each verified milestone, significant change, or project state update to ensure new agents can quickly understand the project and continue development.

---

## CRITICAL: Architecture Understanding

### Hierarchical Alert Processing Structure

THA processes alerts in a **hierarchical tree structure**. The current implementation covers ONE LEAF of this tree:

```
SKYWIND PRODUCTS (Root)
│
├── 4C (Continuous Control Cockpit)          ← Current Product
│   │
│   ├── Quantitative Alerts                   ← IMPLEMENTED
│   │   │   Key: Numbers, counts, monetary values
│   │   │   Output: Key Findings with metrics tables
│   │   │
│   │   ├── BUSINESS_PROTECTION              ← Focus Areas
│   │   │   └── Possible Money Leaks          ← Current Implementation ✅
│   │   ├── BUSINESS_CONTROL
│   │   ├── ACCESS_GOVERNANCE
│   │   ├── TECHNICAL_CONTROL
│   │   └── JOBS_CONTROL
│   │
│   └── Qualitative Alerts                    ← FUTURE (Different Processing)
│       │   Key: Descriptions, patterns, anomalies
│       │   Output: Narrative findings WITHOUT numeric measures
│       │   Processing: Different extraction logic needed
│       │
│       ├── BUSINESS_PROTECTION
│       ├── BUSINESS_CONTROL
│       ├── ACCESS_GOVERNANCE
│       ├── TECHNICAL_CONTROL
│       └── JOBS_CONTROL
│
├── SoDA (Segregation of Duties Analysis)     ← FUTURE PRODUCT
│   │   Key: Role conflicts, access violations
│   │   Artifacts: Different structure than 4C
│   │   Processing: Separate pipeline needed
│   │
│   └── ACCESS_GOVERNANCE Reports
│       ├── Role Conflict Analysis
│       ├── Critical Transaction Access
│       └── User Authorization Review
│
└── Other Products                            ← FUTURE
```

### Processing Differences by Branch

| Branch | Key Characteristics | Extraction Focus |
|--------|--------------------|--------------------|
| **4C Quantitative** | Counts, amounts, metrics | Numbers, totals, concentrations |
| **4C Qualitative** | Patterns, anomalies | Descriptions, WHO/WHAT/WHY |
| **SoDA** | Role conflicts, access | User-role matrices, violations |

**IMPORTANT**: When adding new features, consider:
1. Which **product** it applies to (4C, SoDA, etc.)
2. Which **alert type** it applies to (Quantitative, Qualitative)
3. Which **focus area** it applies to (or all)
4. Whether processing logic differs by branch
5. What output format is appropriate (tables vs narrative)

---

## CRITICAL: Current Work in Progress

### COMPLETED: Discovery Detail Panel Features (2025-12-10)

Enhanced the Critical Discoveries detail panel with 4 new features for better alert investigation:

**Features Implemented:**

| Feature | Description | Data Source |
|---------|-------------|-------------|
| **Alert Explanation** | Business purpose text displayed below alert title | `business_purpose` from Explanation_* file |
| **Output Popover** | JSON popover showing alert output data | `raw_summary_data` from Summary_* file |
| **Params Popover** | JSON popover showing alert parameters | `parameters` from Metadata_* file |
| **Sidebar Filters** | Collapsible filters for Focus Area, Module, Severity | Client-side filtering |
| **Dynamic Risk Score** | Risk explanation based on actual score value | Threshold-based (≥70 high, 40-69 moderate, <40 low) |

**Files Created:**

- `frontend/src/components/JsonDataPopover.tsx` - Reusable popover for JSON data display
- `frontend/src/components/SidebarFilters.tsx` - Collapsible filter component

**Files Modified:**

- `frontend/src/components/DiscoveryDetailPanel.tsx` - Added explanation box, Output/Params buttons, dynamic risk score
- `frontend/src/components/Layout.tsx` - Added filter state and sidebar filter integration
- `frontend/src/components/Layout.css` - Collapsible filter styles
- `frontend/src/pages/AlertDashboard.css` - Explanation box and popover styles (removed blue background)
- `frontend/src/services/api.ts` - Added `business_purpose` and `parameters` to TypeScript interface
- `backend/app/schemas/alert_dashboard.py` - Added fields to Pydantic schema
- `backend/app/api/alert_dashboard.py` - Include new fields in API response
- `frontend/vite.config.ts` - Added `allowedHosts` for Docker browser testing

**Layout Fixes (2025-12-10):**

- Removed blue background from explanation box → now transparent with gray italic text
- Repositioned Output/Params buttons inline with title row
- Fixed title row alignment (center-aligned elements)

**UI State:**

```
┌─────────────────────────────────────────────────────────────────┐
│  Alert Title                    [Output] [Params] [+ Action]    │
│  ℹ Business purpose explanation text (gray italic)              │
├─────────────────────────────────────────────────────────────────┤
│  ⚠ Fraud Indicator Detected - Immediate Review Required         │
├─────────────────────────────────────────────────────────────────┤
│  MODULE | SEVERITY | RECORDS | PERIOD | FINANCIAL EXPOSURE      │
└─────────────────────────────────────────────────────────────────┘
```

**Sidebar Filters:**

- Collapsible header with "⊞ FILTERS ▼" toggle
- Shows active filter count badge when filters applied
- Filter by: Focus Area, Module (SAP), Severity
- Client-side filtering (max 50 discoveries loaded)

---

### COMPLETED: Content Analysis Pipeline → Alert Dashboard Integration (2025-12-05)

The Content Analysis Pipeline now **automatically populates Alert Dashboard tables** when alerts are analyzed via `analyze-and-save` endpoint.

**Integration Flow:**
```
analyze-and-save API → Finding Created → _populate_dashboard_tables()
                                              ↓
                        ┌─────────────────────┴─────────────────────┐
                        ↓                     ↓                     ↓
                  AlertInstance         AlertAnalysis         CriticalDiscovery
                  (alert config)        (results)             (findings)
                        │                     │                     │
                        └─────────────────────┴─────────────────────┤
                                              ↓                     ↓
                                         KeyFinding            ActionItem
                                         (top findings)        (queue)
```

**Key Implementation:**
- **File Modified**: `backend/app/api/content_analysis.py`
- **New Function**: `_populate_dashboard_tables()` (lines 463-691)
- **Integration Points**:
  - Single alert: `analyze_and_save` endpoint (lines 431-444)
  - Batch processing: `_process_batch_job` function (lines 874-880)

**Bug Fix Applied:**
- PostgreSQL `integer out of range` error for `records_affected` field
- Cause: Large counts (99+ billion) exceeded Integer max (2,147,483,647)
- Fix: Capped `records_affected` to PostgreSQL Integer max value

**Verified Working:**
```bash
curl -X POST "http://localhost:3011/api/v1/content-analysis/analyze-and-save" \
  -H "Content-Type: application/json" \
  -d '{"directory_path": "/app/docs/skywind-4c-alerts-output/Applications/FI/200025_001374 - Comparison of monthly sales volume by customer"}'

# Response: {"finding_id":31084,"message":"Finding saved successfully for alert: Comparison of monthly sales volume by customer. Dashboard populated: 1 discoveries, 2 action items.",...}
```

**Dashboard Data (Live):**
- Critical Discoveries: 1
- Alerts Analyzed: 1
- Financial Exposure: $5,000,000
- Avg Risk Score: 75.0 / 100
- Action Items: 2 open (SHORT_TERM priority)

---

### COMPLETED: Unified Dashboard with Tabbed Navigation (2025-12-05)

The Main Dashboard and Alert Dashboard have been **merged into a single unified dashboard** with tabbed navigation.

**Dashboard Layout:**
```
┌─────────────────────────────────────────────────────────────────┐
│  TREASURE HUNT ANALYZER                                         │
├─────────────────────────────────────────────────────────────────┤
│  [ Overview ]  [ Alert Analysis ]  [ Action Queue ]             │
├─────────────────────────────────────────────────────────────────┤
│  TAB CONTENT                                                    │
└─────────────────────────────────────────────────────────────────┘
```

**Tab 1: Overview** (Default)
- KPI Cards: Total Findings, Risk Score (avg), Financial Exposure, Analysis Runs
- Focus Area + Risk Level distribution charts
- Financial Exposure Timeline
- Security Findings Table with sorting

**Tab 2: Alert Analysis**
- KPI Cards: Critical Discoveries, Alerts Analyzed, Financial Exposure (USD), Avg Risk
- Distribution charts: By Severity, By SAP Module
- Critical Discoveries drilldown table

**Tab 3: Action Queue**
- Full-width Action Items Table
- Priority indicators (P1-P5)
- Status badges (OPEN, IN_REVIEW, etc.)

**Files Created:**
- `frontend/src/components/DashboardTabs.tsx` - Tab navigation component

**Files Modified:**
- `frontend/src/pages/Dashboard.tsx` - Added tabs and merged Alert Dashboard content
- `frontend/src/pages/AlertDashboard.css` - Improved font sizes for readability
- `frontend/src/styles/dashboard.css` - Added tab styling
- `frontend/src/App.tsx` - Removed Alert Dashboard route
- `frontend/src/components/Layout.tsx` - Removed Alert Dashboard nav link

**Files Deleted:**
- `frontend/src/pages/AlertDashboard.tsx` - Content merged into Dashboard.tsx

**Font Size Improvements (AlertDashboard.css):**
| Element | Before | After |
|---------|--------|-------|
| Distribution labels | 11px | 12px |
| Table headers | 10px | 11px |
| Table body | 13px | 14px |
| Badges | 10px | 11px |
| Priority circles | 28px | 32px |

**Verified Working:**
- All 3 tabs render correctly
- Tab switching works smoothly
- Data loads on tab activation (conditional queries)
- Critical Discoveries table displays
- Action Queue table with priority badges
- Screenshot saved: `.playwright-mcp/dashboard-action-queue-tab.png`

---

### Database Schema: Alert Analysis (10 tables)

A comprehensive data layer for storing parsed alert analysis results and EI vocabulary catalog:

| Table | Purpose |
|-------|---------|
| `clients` | Client entities (e.g., Safal Group) |
| `source_systems` | SAP source systems (PS4, ECP, BIP) |
| `exception_indicators` | EI definitions (SW_10_01_ORD_VAL_TOT) |
| `ei_vocabulary` | LLM-generated ABAP code interpretations |
| `alert_instances` | Alert configurations (EI + parameters) |
| `alert_analyses` | Analysis results per execution |
| `critical_discoveries` | Top findings requiring attention |
| `key_findings` | Top N findings per analysis |
| `concentration_metrics` | Concentration data by dimension |
| `action_items` | Investigation queue with status |

**API Endpoints (Alert Dashboard):**

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/alert-dashboard/kpis` | GET | Dashboard KPI summary |
| `/alert-dashboard/critical-discoveries` | GET | Drilldown for critical findings |
| `/alert-dashboard/action-queue` | GET | Open action items |
| `/alert-dashboard/clients` | GET/POST | Client management |
| `/alert-dashboard/source-systems` | GET/POST | Source system management |
| `/alert-dashboard/exception-indicators` | GET/POST | EI catalog |
| `/alert-dashboard/ei-vocabulary` | GET/POST | EI vocabulary entries |
| `/alert-dashboard/alert-instances` | GET/POST | Alert instances |
| `/alert-dashboard/analyses` | GET/POST | Analysis results |
| `/alert-dashboard/action-items` | GET/POST/PATCH | Action item CRUD |

---

### Previous Development: Content Analysis Pipeline (IMPLEMENTED)

A scalable pipeline for processing hundreds of 4C alerts with automated analysis and report generation.

**New API Endpoints (WORKING):**

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/content-analysis/scan-folders` | POST | Discover alert folders in directory tree |
| `/content-analysis/analyze-and-save` | POST | Analyze single alert → DB + Markdown |
| `/content-analysis/analyze-batch` | POST | Batch process multiple alerts |
| `/content-analysis/batch-status/{job_id}` | GET | Check batch job progress |
| `/content-analysis/batch-jobs` | GET | List all batch jobs |

**Report Levels:**
- `summary`: Quick metrics extraction, no LLM (low cost, fast)
- `full`: Complete LLM-generated Key Findings report (higher cost)

**Output:**
- **Database**: Finding, RiskAssessment, MoneyLossCalculation records
- **Markdown**: Reports saved to `/app/storage/reports/`

**Test Results (2025-11-28):**
- ✅ `scan-folders`: Found all 4C alert folders
- ✅ `analyze-and-save`: Successfully analyzed, saved to DB, generated markdown
- ✅ `analyze-batch`: Processed 2 alerts in parallel, both successful

**Enhanced ArtifactReader (Phase 3 COMPLETE):**
- Dynamic column detection for varying alert types
- Automatic SAP field code extraction (e.g., "Amount (DMBTR)" → DMBTR)
- Key metric identification (currency, count, balance columns)
- Statistics calculation (sum, min, max, avg) for numeric columns
- New classes: `ColumnType`, `ColumnInfo`, `SummaryData`
- Backward compatible (still provides `raw_text` for existing code)

**Finding Model Updates (Phase 4 COMPLETE):**

New database columns added to `findings` table:
| Field | Type | Purpose |
|-------|------|---------|
| `source_alert_id` | VARCHAR | Alert ID e.g., "200025_001372" |
| `source_alert_name` | VARCHAR | Alert name e.g., "Rarely Used Vendors" |
| `source_module` | VARCHAR | SAP module e.g., "FI", "MM", "SD" |
| `source_directory` | VARCHAR | Full path to alert folder |
| `markdown_report` | TEXT | Full markdown content |
| `report_path` | VARCHAR | Path to saved markdown file |
| `report_level` | VARCHAR | "summary" or "full" |
| `key_findings_json` | JSONB | Structured findings (risk_score, metrics, etc.) |
| `analysis_status` | VARCHAR | "pending", "analyzing", "completed", "failed" |
| `analysis_error` | TEXT | Error message if failed |
| `analyzed_at` | TIMESTAMP | When analysis completed |

**Note**: Columns added via direct SQL (no Alembic migration) due to read-only container filesystem.

**Frontend Alert Analysis UI (Phase 6 COMPLETE + BUG FIXES 2025-11-29):**

New page at `/alert-analysis` with features:
- **Scan Section**: Input base path, scan for alert folders recursively
- **Alert Table**: Shows module, alert name, ID, completeness status
- **Module Filter**: Dropdown to filter by SAP module (FI, MD, MM, PUR, SD)
- **Multi-select**: Checkboxes with Select All / Clear Selection
- **Report Level**: Dropdown for summary (fast) vs full (LLM)
- **Batch Analysis**: Process multiple selected alerts with progress bar
- **Results**: Shows success/failure with links to created findings

**UI Theme (2025-11-29):**
- Light theme with professional enterprise styling
- CSS variables for consistent theming
- Blue accent color (#2563eb), white backgrounds
- `AlertAnalysis.css` - 400+ lines of styled CSS

**Bug Fix (2025-11-29):**
- Fixed money loss calculation showing $603B → now correctly shows capped estimates ($10M-$50M)
- See `scoring_engine.py` → `_estimate_money_loss()` method

Files created/modified:
- `frontend/src/pages/AlertAnalysis.tsx` - NEW page component
- `frontend/src/pages/AlertAnalysis.css` - NEW CSS with light enterprise theme
- `frontend/src/services/api.ts` - Added content analysis API functions
- `frontend/src/App.tsx` - Added route
- `frontend/src/components/Layout.tsx` - Added nav item

---

### Previous Context: Alert Interpretation Comparison

The user compared **AI interpretation vs User interpretation** of real alerts. Key findings from "Negative Profit Deal" analysis:
- Focus Area: BUSINESS_CONTROL
- Severity: CRITICAL
- Total Loss: $14,152,997 (2,044 line items)
- Key Pattern: 59% zero-price items, 39% manual price overrides

---

### Previous Context: Scoring Rules (Still Pending)

1. **Severity Base Scores (UPDATED - not yet implemented)**:
   - Critical: 90 (was 85)
   - High: 75 (was 65)
   - Medium: 60 (was 45)
   - Low: 50 (was 25)

2. **Count Adjustment must consider BACKDAYS parameter**:
   - Alert parameters are in `Metadata_*` file
   - BACKDAYS = history depth (e.g., BACKDAYS=1 means yesterday+today)
   - Raw count alone is MISLEADING - must normalize by BACKDAYS
   - Example: 1,943 vendors in 1 day vs 1,943 vendors in 30 days = VERY different risk

3. **Money Adjustment thresholds** - User wants explanation/refinement:
   - $1M+: +20 points
   - $100K+: +15 points
   - $10K+: +10 points

4. **Missing Documentation**: User mentioned `docs/about_skywind/TXT` folder with Skywind alert parameter documentation - THIS FOLDER DOES NOT EXIST IN THE REPO. Ask user to provide.

---

## Project Overview

**Name**: Treasure Hunt Analyzer (THA)
**Purpose**: Enterprise system for analyzing Skywind platform alerts (4C) and reports (SoDA), providing insights across 6 focus areas with risk assessment and financial impact analysis.

**Tech Stack**:
- **Backend**: FastAPI (Python 3.11), PostgreSQL 15, SQLAlchemy 2.0
- **Frontend**: React 18, TypeScript, Vite, Bootstrap 5, Recharts
- **Infrastructure**: Docker Compose (dev), AWS (prod)
- **AI/ML**: OpenAI/Anthropic LLMs (optional), Pattern-based fallback

---

## Current Project State (VERIFIED 2025-11-29)

### Working Features ✅

1. **Alert Analysis Pipeline UI (NEW 2025-11-28, FIXED 2025-11-29)**
   - Alert Analysis page at http://localhost:3010/alert-analysis
   - Scan directories for alert folders recursively
   - Module filtering (FI, MM, SD, PUR, MD)
   - Multi-select with Select All / Clear Selection
   - Batch analysis with progress tracking
   - Light enterprise theme (white backgrounds, blue accents)
   - **Money loss calculation fixed** - shows capped estimates ($10M-$50M) instead of absurd values

2. **Multi-File Artifact Upload (UI)**
   - Upload page at http://localhost:3010/upload
   - Add files one-by-one (Code, Explanation, Metadata, Summary)
   - Color-coded file categorization (green=found, yellow=pending)
   - Flexible file name matching (handles spaces after prefix)
   - Auto-analyze after upload

3. **Content Analyzer (Pattern-Based)**
   - Reads 4 artifact files from uploaded directory
   - Extracts text from .txt, .docx, .xlsx files
   - Classifies into 6 Focus Areas (keyword matching)
   - Extracts counts (handles comma-separated: "1,943")
   - Extracts monetary amounts (handles $45M format)
   - Calculates risk score with breakdown

4. **End-to-End Flow WORKING**
   - Upload 4 artifacts via UI → Analyze → Dashboard shows results
   - Example tested: "Rarely Used Vendors" alert
   - Result: BUSINESS_CONTROL, 1,943 vendors, $45,000,000 exposure, Risk Score 80

5. **Dashboard (VERIFIED)**
   - KPI cards: Total Findings, Risk Score, Financial Exposure, Analysis Runs
   - Focus Area distribution chart
   - Risk Level analysis chart
   - Filters (Focus Area, Severity, Status, Date Range)

6. **API Endpoints (VERIFIED)**
   - `POST /api/v1/ingestion/upload-artifacts` - Multi-file upload
   - `POST /api/v1/content-analysis/analyze-directory` - Analyze without saving
   - `POST /api/v1/content-analysis/analyze-and-save` - Analyze and persist to DB
   - `GET /api/v1/dashboard/kpis` - Dashboard metrics
   - `GET /api/v1/analysis/findings` - Findings list
   - `DELETE /api/v1/maintenance/data-sources?confirm=true` - Clear all data

### Access Points (CURRENT)

| Service | URL |
|---------|-----|
| Frontend | http://localhost:3010 |
| Backend API | http://localhost:3011 |
| Swagger Docs | http://localhost:3011/docs |
| Health Check | http://localhost:3011/health |

---

## 6 Focus Areas (Classification)

| Focus Area | Description | Keywords |
|------------|-------------|----------|
| **BUSINESS_PROTECTION** | Fraud, cybersecurity, vendor manipulation | fraud, theft, unauthorized, manipulation, suspicious |
| **BUSINESS_CONTROL** | Process bottlenecks, vendor/customer management | vendor, customer, master data, invoice, payment, balance |
| **ACCESS_GOVERNANCE** | SoD violations, authorization control | sod, segregation of duties, privilege, authorization |
| **TECHNICAL_CONTROL** | System dumps, infrastructure issues | memory dump, abap dump, cpu usage, system crash |
| **JOBS_CONTROL** | Job performance, resource utilization | job failed, batch job, background job, job runtime |
| **S/4HANA_EXCELLENCE** | Post-migration safeguarding, configuration drift | s/4hana, migration, hana, fiori, custom code, adaptation |

**Classification Logic**: `backend/app/services/content_analyzer/llm_classifier.py` → `analyze_without_llm()` method

---

## Analysis Principles (User-Defined)

### Core Analyzer Workflow

```
PHASE 1: CONTEXT LOADING
├── Load general TH knowledge (/docs/th-context/readmore/*)
└── Alert-specific context from 4 artifacts

PHASE 2: ARTIFACT READING (Sequential)
├── 1. Code_*       → Alert logic (ABAP/SQL)
├── 2. Explanation_* → Business context (WHY it matters)
├── 3. Metadata_*   → Parameters (BACKDAYS, filters)
└── 4. Summary_*    → ACTUAL OUTPUT TO ANALYZE

PHASE 3: ANALYSIS
├── Summary_* is PRIMARY data source
├── Other artifacts provide CONTEXT
├── Classify into 1 of 6 Focus Areas
└── Perform Qualitative + Quantitative analysis

PHASE 4: SCORING
├── Qualitative: "What happened?" → Event description
└── Quantitative: "How much/many?" → Counts, amounts
```

### Qualitative vs Quantitative Examples

| Type | Alert | Key Indicator |
|------|-------|---------------|
| Qualitative | "Inactive Vendor" | Problem description, cleanup needed |
| Quantitative | "Inactive Vendor with High Balance" | **$6.7M** at risk, specific amounts |

---

## Recent Session Work (2025-11-26)

### Files Modified

1. **backend/app/api/content_analysis.py**
   - Added `analyze-and-save` endpoint
   - Fixed DataSource model fields (file_format, data_type instead of file_type)
   - Uses correct API for persisting findings to database

2. **backend/app/services/content_analyzer/analyzer.py**
   - Fixed `_fallback_analysis()` to extract metrics from ALL artifacts (not just summary)
   - Added `monetary_amount` to quantitative_analysis dict
   - Improved `_fallback_classification()` keywords

3. **backend/app/services/content_analyzer/llm_classifier.py**
   - Updated `analyze_without_llm()` keywords:
     - Added vendor/customer/balance/financial to BUSINESS_CONTROL
     - Made TECHNICAL_CONTROL keywords more specific (avoid generic "system")

4. **backend/app/services/content_analyzer/scoring_engine.py**
   - Fixed count regex to handle comma-separated numbers ("1,943" → 1943)
   - Pattern: `r'([\d,]+)\s+(?:records?|items?|vendors?|...)'`

5. **frontend/src/pages/Upload.tsx**
   - Added multi-file artifact upload section
   - Add files one-by-one workflow
   - Color-coded categorization (Code/Explanation/Metadata/Summary)
   - Fixed API URLs to use `http://localhost:3011/api/v1`
   - Flexible file name matching (handles "Metadata " with space)

### Commits Made (Branch: claude/claude-md-miecwc4mecipjiww-01E2YVoZHeHvYiRZUEUYKn4j)

1. `Fix DataSource model fields in analyze-and-save endpoint`
2. `Improve quantitative extraction and focus area classification`
3. `Fix classification keywords and count regex for comma-separated numbers`
4. `Add multi-file artifact upload to Upload page`
5. `Update Upload page to add artifact files one-by-one`
6. `Fix API URLs in Upload page to use correct backend URL`
7. `Make artifact file categorization more flexible (handle spaces after prefix)`

---

## Testing Commands

### Test Content Analyzer (CLI)

```bash
# Upload artifacts via Swagger UI first, get artifacts_path

# Analyze without saving (see full output)
curl -X POST "http://localhost:3011/api/v1/content-analysis/analyze-directory" \
  -H "Content-Type: application/json" \
  -d '{"directory_path": "/app/storage/artifacts/YOUR_PATH", "use_llm": false}'

# Analyze and save to database
curl -X POST "http://localhost:3011/api/v1/content-analysis/analyze-and-save" \
  -H "Content-Type: application/json" \
  -d '{"directory_path": "/app/storage/artifacts/YOUR_PATH", "use_llm": false}'
```

### Clear Database and Re-test

```bash
# Clear all data
curl -X DELETE "http://localhost:3011/api/v1/maintenance/data-sources?confirm=true"

# Re-initialize with seed data (optional)
docker compose exec backend python -m app.utils.init_db
```

### Rebuild After Code Changes

```bash
# Pull latest code
git pull origin claude/claude-md-miecwc4mecipjiww-01E2YVoZHeHvYiRZUEUYKn4j

# Rebuild backend (fast - uses cache)
docker compose build backend && docker compose up -d backend

# Rebuild frontend (fast - uses cache)
docker compose build frontend && docker compose up -d frontend

# Full rebuild (slow - no cache)
docker compose build --no-cache backend && docker compose up -d backend
```

---

## Current Scoring Logic (TO BE REFINED)

### Risk Score Calculation

```python
# scoring_engine.py

# Base scores by severity
SEVERITY_BASE_SCORES = {
    "Critical": 85,  # USER WANTS: 90
    "High": 65,      # USER WANTS: 75
    "Medium": 45,    # USER WANTS: 60
    "Low": 25,       # USER WANTS: 50
}

# Count adjustment
if count >= 1000: +15
elif count >= 500: +10
elif count >= 100: +5

# Money adjustment
if amount >= 1_000_000: +20
elif amount >= 100_000: +15
elif amount >= 10_000: +10
elif amount >= 1_000: +5

# Focus area multiplier
FOCUS_AREA_MULTIPLIERS = {
    "BUSINESS_PROTECTION": 1.2,
    "BUSINESS_CONTROL": 1.0,
    "ACCESS_GOVERNANCE": 1.15,
    "TECHNICAL_CONTROL": 0.9,
    "JOBS_CONTROL": 0.85,
}

final_score = (base + count_adj + money_adj) * multiplier
```

### PENDING: Normalize Count by BACKDAYS

The user explained that raw count must be normalized by BACKDAYS parameter from Metadata file:

```
Normalized_Count = Raw_Count / BACKDAYS
Risk = f(Normalized_Count, ...)
```

**This is NOT YET IMPLEMENTED.**

---

## Key Files Reference

### Content Analysis Pipeline (Updated 2025-11-29)

| File | Purpose |
|------|---------|
| **`backend/app/api/content_analysis.py`** | **Pipeline API endpoints (scan, analyze, batch)** |
| **`backend/app/services/content_analyzer/report_generator.py`** | **Markdown report generation (summary/full)** |
| `backend/app/services/content_analyzer/analyzer.py` | Main analysis orchestrator |
| `backend/app/services/content_analyzer/llm_classifier.py` | Focus area classification |
| **`backend/app/services/content_analyzer/scoring_engine.py`** | **Risk scoring + Money Loss calculation (FIXED 2025-11-29)** |
| `backend/app/services/content_analyzer/artifact_reader.py` | File parsing (txt, docx, xlsx) |

### Frontend (Updated 2025-11-29)

| File | Purpose |
|------|---------|
| **`frontend/src/pages/AlertAnalysis.tsx`** | **Alert Analysis UI - scan, select, batch analyze** |
| **`frontend/src/pages/AlertAnalysis.css`** | **Light theme CSS (400+ lines) - enterprise styling** |
| `frontend/src/pages/Upload.tsx` | Multi-file upload UI |
| `frontend/src/pages/Dashboard.tsx` | Dashboard display |
| `frontend/src/services/api.ts` | API client with content analysis functions |

### Documentation

| File | Purpose |
|------|---------|
| `docs/th-context/readmore/*.md` | Focus Area definitions |
| `docs/analysis/*.md` | Generated analysis reports |
| `docs/skywind-4c-alerts-output/` | Sample 4C alert artifacts |

### Configuration

| File | Purpose |
|------|---------|
| `docker-compose.yml` | Docker setup (includes docs volume mount) |
| `docs/th-context/analysis-rules/templates/quantitative-alert.yaml` | Key Findings report template (v1.2) |

---

## Next Steps (Prioritized)

### Immediate (Current Session)

1. **✅ Complete AI interpretation of "Negative Profit Deal" alert** - DONE
2. **⏳ Receive user's interpretation** for comparison
3. **Compare AI vs User interpretation** - identify gaps
4. **Analyze remaining 2 alerts** (user mentioned 3 total)

### After Comparison Exercise

5. **Implement Content Analyzer improvements** based on identified gaps
6. **Implement updated severity base scores** (90/75/60/50)
7. **Add BACKDAYS parameter extraction** from Metadata_* file
8. **Normalize count by BACKDAYS** for meaningful risk scoring

### Short-term

9. **Create rules database structure** for storing scoring logic
10. **Define scoring rules for each Focus Area** (5 total)
11. **Improve qualitative analysis** (severity reasoning, what_happened)

### Medium-term

12. **Enable LLM mode** for better classification (requires API key)
13. **Add SoDA report support** (different artifact structure)
14. **Create feedback loop** for iterative improvement

---

## Known Issues

1. **Metadata parameter extraction not implemented** - BACKDAYS not used
2. **Severity always defaults to "Medium"** - not derived from content
3. ~~**Money adjustment thresholds are arbitrary**~~ - **FIXED 2025-11-29**: Money loss now uses focus area loss factors (5%/2%/1%) with severity multipliers and reasonable caps ($10M-$50M max)
4. **LLM mode disabled** - no API key configured in Docker env
5. **Frontend theme applied via skill** - Used `frontend-design` skill for AlertAnalysis.css but initial dark theme was inappropriate for enterprise app; reverted to light theme

---

## Context Documents

### Available (Read These First)
- **`docs/th-context/skywind-4c-knowledge.md`** - Consolidated Skywind 4C knowledge base (CREATED 2025-11-27)
  - Core terminology (Exception Indicator, Alert Instance, Alert Template)
  - Alert parameters (BACKDAYS, FORWDAYS, DURATION, etc.)
  - Alert artifact structure (Code, Explanation, Metadata, Summary)
  - SAP module reference (SD, FI, MM fields)
  - Analysis guidelines for THA

### Source Documentation (Raw)
- `docs/about_skywind/TXT/*` - Original Skywind documentation (70+ files)
- `docs/about_skywind/HTML/*` - Raw HTML pages from help.skywind.com

### Still Missing
- `Core Principles of THA Analysis.md` - On user's Windows machine

---

## Git Branch

**Current Working Branch**: `claude/content-analyzer-alerts-01BpHADP1KyVMhdC8e6K2bsf`

**Previous Branch**: `claude/claude-md-miecwc4mecipjiww-01E2YVoZHeHvYiRZUEUYKn4j` (merged to main)

To continue work:

```bash
git checkout claude/content-analyzer-alerts-01BpHADP1KyVMhdC8e6K2bsf
git pull origin claude/content-analyzer-alerts-01BpHADP1KyVMhdC8e6K2bsf
```

---

## Changelog

### 2025-12-10 (COMPREHENSIVE AUDIT + FIXES)

**Audit Completed:**

Full 3-round audit performed with 5 parallel agents. Report saved to `AUDIT_REPORT_2025-12-10.md`.

| Category | Issues Found | Severity |
|----------|-------------|----------|
| Documentation | 12 | LOW-MEDIUM |
| Backend Code | 11 | LOW-MEDIUM |
| Frontend Code | 7 | MEDIUM-HIGH |
| Database Migrations | 1 CRITICAL | HIGH |
| File References | 0 | NONE |
| **TOTAL** | **31** | **MEDIUM** |

**Overall Health Score: 7.5/10**

**Critical Finding:** 10 legacy models (DataSource, Finding, FocusArea, Alert, etc.) lack Alembic migrations - created by init_db.py instead.

**Fixes Applied:**

1. **ActionItemModal prop type mismatch** (HIGH)
   - Created new `CreateActionItemModal.tsx` for creating action items from discoveries
   - `AlertDiscoveries.tsx` now uses CreateActionItemModal instead of ActionItemModal
   - Added `ActionItemCreate` interface to api.ts
   - Added `createActionItem()` and `updateActionItem()` API functions

2. **AlertAnalysis page not routed** (HIGH)
   - Added route `/alert-analysis` to `App.tsx`
   - Added navigation link in `Layout.tsx`

3. **Missing finding_id in ActionItem interface** (MEDIUM)
   - Added `finding_id?: number` to ActionItem interface in api.ts

4. **Unused imports in content_analysis.py** (LOW)
   - Removed unused `create_content_analyzer` import
   - Removed unused `AlertArtifacts` import
   - Removed duplicate `datetime` import at line 380

**Files Created:**
- `frontend/src/components/CreateActionItemModal.tsx`
- `AUDIT_REPORT_2025-12-10.md`

**Files Modified:**
- `frontend/src/services/api.ts` - Added ActionItemCreate, finding_id, createActionItem, updateActionItem
- `frontend/src/pages/AlertDiscoveries.tsx` - Use CreateActionItemModal
- `frontend/src/App.tsx` - Added AlertAnalysis route
- `frontend/src/components/Layout.tsx` - Added AlertAnalysis nav link
- `backend/app/api/content_analysis.py` - Removed unused imports

**Pending Items** (not critical):
- ~~Create Alembic migration for 10 legacy models~~ ✅ DONE
- ~~Remove 6 unused frontend API functions~~ ✅ Kept as placeholders
- ~~Remove 6 unused backend config settings~~ ✅ Kept for future features (S3, auth)
- ~~Standardize `docker compose` syntax in docs~~ ✅ DONE

**Additional Fixes Applied (Phase 2):**

5. **Legacy models migration** (CRITICAL)
   - Created `002_add_legacy_treasure_hunt_tables.py` migration
   - Covers 13 tables: focus_areas, issue_types, issue_groups, data_sources, alerts, alert_metadata, soda_reports, soda_report_metadata, findings, risk_assessments, money_loss_calculations, analysis_runs, audit_logs

6. **Standardized docker compose syntax** (LOW)
   - Updated 9 markdown files to use `docker compose` (space) instead of `docker-compose` (hyphen)
   - Files: CLAUDE.md, QUICK_START.md, DEPLOYMENT.md, README.md, QUICK_TEST.md, TESTING_GUIDE.md, TESTING_CHECKLIST.md, DOCKER_SETUP_GUIDE.md, APPLICATION_FLOW_MAP.md

**Files Created (Phase 2):**
- `backend/alembic/versions/002_add_legacy_treasure_hunt_tables.py`

---

### 2025-12-10 (DISCOVERY DETAIL FEATURES)

**New Features:**

- Added Alert Explanation box showing business_purpose from Explanation_* file
- Added Output popover button to display raw_summary_data JSON
- Added Params popover button to display parameters JSON from Metadata
- Added collapsible sidebar filters (Focus Area, Module, Severity)
- Added dynamic Risk Score explanation based on score thresholds

**Layout Fixes:**

- Removed blue background from explanation box (now transparent with gray italic text)
- Repositioned Output/Params buttons inline with title row
- Fixed title row alignment to center elements

**Files Created:**

- `frontend/src/components/JsonDataPopover.tsx`
- `frontend/src/components/SidebarFilters.tsx`

**Files Modified:**

- `frontend/src/components/DiscoveryDetailPanel.tsx`
- `frontend/src/components/Layout.tsx`
- `frontend/src/components/Layout.css`
- `frontend/src/pages/AlertDashboard.css`
- `frontend/src/services/api.ts`
- `backend/app/schemas/alert_dashboard.py`
- `backend/app/api/alert_dashboard.py`
- `frontend/vite.config.ts`

---

### 2025-12-05 (DASHBOARD MERGE COMPLETE)

**Unified Dashboard with Tabbed Navigation:**

Merged the separate Alert Dashboard into the Main Dashboard as a unified experience with 3 tabs.

**What Changed:**
- Created `DashboardTabs.tsx` component with Overview, Alert Analysis, Action Queue tabs
- Modified `Dashboard.tsx` to include tab navigation and conditional rendering
- Added Alert Dashboard API queries with conditional enabling (only fetch when tab is active)
- Improved font sizes in `AlertDashboard.css` for better readability
- Added tab styles to `dashboard.css` with Skywind red accent color
- Removed `/alert-dashboard` route from `App.tsx`
- Removed Alert Dashboard nav link from `Layout.tsx`
- Deleted `AlertDashboard.tsx` (content merged into Dashboard.tsx)

**Tab Content:**
- **Overview**: Original dashboard - KPIs, charts, findings table
- **Alert Analysis**: Critical Discoveries, severity/module distributions, discoveries table
- **Action Queue**: Action items table with priority badges and status

**Verification:**
- All 3 tabs render correctly
- Tab switching is smooth
- Data loads on tab activation
- Screenshot: `.playwright-mcp/dashboard-action-queue-tab.png`

---

### 2025-12-05 (INTEGRATION COMPLETE - Earlier)

**Content Analysis Pipeline → Alert Dashboard Integration:**

The analyze-and-save endpoint now automatically populates Alert Dashboard tables when processing alerts.

**New Implementation:**
- Added `_populate_dashboard_tables()` helper function in `content_analysis.py`
- Creates: AlertInstance, AlertAnalysis, CriticalDiscovery, KeyFinding, ActionItem records
- Integrated into both single alert (`analyze_and_save`) and batch processing (`_process_batch_job`)

**Bug Fix:**
- Fixed PostgreSQL `integer out of range` error for `records_affected` field
- Large counts (99+ billion) were exceeding Integer max (2,147,483,647)
- Solution: Capped values to PostgreSQL Integer maximum

**Verification:**
- Dashboard UI accessible at http://localhost:3010/alert-dashboard
- KPI cards showing: 1 discovery, 1 alert, $5M exposure, 75 risk score
- Action Queue showing: 2 open SHORT_TERM items
- Screenshot saved: `.playwright-mcp/alert-dashboard-working.png`

**Alert Analysis Dashboard Implementation (Earlier):**

A comprehensive dashboard system for visualizing quantitative alert analysis results with EI vocabulary catalog.

**Database Schema (10 new tables):**
1. `clients` - Client entities with relationships to source systems
2. `source_systems` - SAP source systems (PS4, ECP, BIP) per client
3. `exception_indicators` - EI definitions (function names, modules)
4. `ei_vocabulary` - LLM-generated ABAP code interpretations with versioning
5. `alert_instances` - Alert configurations (EI + parameters from Metadata)
6. `alert_analyses` - Analysis results with severity, risk_score, financial_impact
7. `critical_discoveries` - High-signal findings requiring immediate attention
8. `key_findings` - Top N findings per analysis with categories
9. `concentration_metrics` - Concentration data by dimension (SALES_ORG, CUSTOMER)
10. `action_items` - Investigation queue with status workflow

**Backend Implementation:**
- Created 9 SQLAlchemy models in `backend/app/models/`
- Created Pydantic schemas in `backend/app/schemas/alert_dashboard.py`
- Created API endpoints in `backend/app/api/alert_dashboard.py`
- Alembic migration applied successfully

**Frontend Implementation:**
- AlertDashboard page component (`frontend/src/pages/AlertDashboard.tsx`)
- CSS styles (`frontend/src/pages/AlertDashboard.css`)
- API functions in `frontend/src/services/api.ts`
- Route and navigation added

**KPI Dashboard Features:**
- 4 KPI cards: Critical Discoveries, Alerts Analyzed, Financial Exposure, Avg Risk Score
- 3 distribution charts: By Severity, By Module, By Focus Area
- Critical Discoveries drilldown table
- Action Queue table with priority indicators
- Trend Analysis placeholder with hierarchy display

**API Verified Working:**
```bash
curl http://localhost:3011/api/v1/alert-dashboard/kpis
# Returns: total_critical_discoveries, total_alerts_analyzed, etc.
```

**Note:** Frontend rebuild required for new UI components (npm registry had transient errors during build).

---

### 2025-11-29 (Previous Session)

**Git**: Pushed to main (commit b4a88bf). Pull on other machine with `git pull origin main`.

**Bug Fixes:**
- **FIXED**: Money loss calculation showing absurd values ($603 billion instead of reasonable estimates)
  - Root cause: `scoring_engine.py` → `_estimate_money_loss()` was returning raw `monetary_amount` directly
  - Fix: Applied loss factor percentages by focus area (5% fraud, 2% business control, etc.)
  - Fix: Added severity multipliers (Critical=3x, High=2x, Medium=1x, Low=0.5x)
  - Fix: Capped estimates at reasonable amounts ($10M for normal, $50M max for very large transactions)
  - Result: Money loss went from $603B to $50M (properly capped)

**UI Improvements:**
- **REVERTED**: AlertAnalysis.css from dark theme to light theme
  - User feedback: "revert to the white theme - the dark theme is inappropriate"
  - Changed from dark "Command Center" theme (black backgrounds, cyan accents)
  - New light theme: white backgrounds (#ffffff), blue accents (#2563eb), proper enterprise styling
  - Kept improved CSS structure with CSS variables, professional component styling

**Files Modified:**
- `backend/app/services/content_analyzer/scoring_engine.py` - Critical bug fix in `_estimate_money_loss()`
- `frontend/src/pages/AlertAnalysis.css` - Light theme with professional styling

**Testing Verified:**
- API call to analyze alert now shows $50M instead of $603B
- Frontend displays correctly with light theme
- All batch analysis functionality working

**Ready for Deep-Dive Testing**: User indicated they want to "deep dive test" the analysis functions after these fixes.

---

### 2025-11-28 (Previous Session)
- **IMPLEMENTED**: Content Analysis Pipeline for scalable 4C alert processing
  - New endpoints: `scan-folders`, `analyze-batch`, `batch-status`, `batch-jobs`
  - Enhanced `analyze-and-save` with `report_level` parameter (summary/full)
  - Background processing for batch jobs
- **CREATED**: `backend/app/services/content_analyzer/report_generator.py`
  - Generates markdown reports following Key Findings template
  - Supports summary (no LLM) and full (LLM-generated) modes
  - Saves to `/app/storage/reports/`
- **UPDATED**: `docker-compose.yml` - Added docs volume mount for alert access
- **DOCUMENTED**: Hierarchical alert processing structure in llm_handover.md
  - Product (4C, SoDA) → Alert Type (Quantitative, Qualitative) → Focus Area
  - Current implementation covers: 4C > Quantitative > BUSINESS_PROTECTION
- **TESTED**: End-to-end pipeline working
  - scan-folders: Found all alert folders
  - analyze-and-save: Analyzed, saved to DB, generated markdown
  - analyze-batch: Processed 2 alerts successfully

### 2025-11-27
- **CREATED**: `docs/th-context/skywind-4c-knowledge.md` - Consolidated Skywind 4C knowledge base
  - Read all 70+ TXT files from docs/about_skywind/
  - Documented core terminology (EI, AI, Alert Template)
  - Documented parameters (BACKDAYS, FORWDAYS, DURATION)
  - BACKDAYS clarification: It's a filter for time window depth, NOT a divisor for normalization
- **IN PROGRESS**: Alert Interpretation Comparison Exercise
- **CREATED**: `docs/analysis/SD_Negative_Profit_Deal_Analysis.md` - Full AI analysis document
- **ANALYZED**: "Negative Profit Deal" alert (SD Module, ID: 200025_001441)
  - 2,044 line items, $14.15M total loss
  - Patterns: 59% zero-price, 39% manual override
  - Fraud indicator: $8.1M single transaction to KAMURU TRADING
  - Concentration: KE01 = 81% of loss
  - BACKDAYS = 365 (data from past year)
- **WORKFLOW**: User comparing AI vs User interpretation to improve Content Analyzer
- **PENDING**: User's interpretation for comparison
- **PENDING**: 2 more alerts to analyze

### 2025-11-26 (Session End)
- **WORKING**: End-to-end flow: Upload 4 artifacts → Analyze → Dashboard shows results
- **WORKING**: Multi-file upload UI (add files one-by-one)
- **WORKING**: Content Analyzer with pattern-based classification
- **FIXED**: Quantitative extraction ($45M, 1,943 vendors from text)
- **FIXED**: Focus area classification (vendor alerts → BUSINESS_CONTROL)
- **FIXED**: Comma-separated number parsing (1,943 not 943)
- **FIXED**: API URLs in Upload page (port 3011)
- **FIXED**: File categorization (handles "Metadata " with space)
- **TESTED**: "Rarely Used Vendors" alert → $45M exposure, Risk 80
- **FIXED**: Severity base scores now consistent (90/75/60/50) across all files:
  - `risk_scorer.py` - CRITICAL=90, HIGH=75, MEDIUM=60, LOW=50
  - `content_analyzer/analyzer.py` - fallback scores aligned
  - `scoring_engine.py` - source of truth (was already correct)
- **IN PROGRESS**: Defining BUSINESS_PROTECTION scoring rules
- **PENDING**: BACKDAYS parameter extraction from Metadata file (for context, not normalization)

### 2025-11-26 (Earlier)
- **ADDED**: Intelligent Content Analyzer module
- **ADDED**: Content Analysis API endpoints
- **ADDED**: Multi-file upload endpoint
- **FIXED**: Content analyzer `__init__.py` missing exports

### 2025-11-25
- **UPDATED**: Frontend port 3010, Backend port 3011
- **UPDATED**: Docker Compose with VITE_API_BASE_URL

### 2025-11-23
- **FIXED**: Docker environment setup
- **FIXED**: Database schema mismatch
- **VERIFIED**: Dashboard fully functional

---

**END OF HANDOVER DOCUMENT**

*This document should be updated after each verified milestone. Keep it accurate for seamless AI agent collaboration.*
